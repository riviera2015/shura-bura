{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/header.png\">\n",
    "\n",
    "<h1><center>Алгоритмы интеллектуальной обработки больших объемов данных</center></h1>\n",
    "<hr>\n",
    "<h2><center>Линейные модели (практика)</center></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from ipywidgets import interact, IntSlider, fixed\n",
    "except ImportError:\n",
    "    print u'Так надо'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Линейная регрессия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Пример: Стоимость автомобиля"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите [тренировочные данные](http://bit.ly/1gIQs6C) и [тестовые данные](http://bit.ly/IYPHrK) - уже знакомые нам данные по автомобилям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('http://bit.ly/1gIQs6C')\n",
    "df_test = pd.read_csv('http://bit.ly/IYPHrK')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.plot(x='mileage', y='price', kind='scatter', s=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Кажется, что между стоимостью и пробегом зависимость линейная - давайте ее найдем!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = df_train.mileage.values.reshape(-1, 1)\n",
    "y_train = df_train.price.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'Модель:\\nprice = %.2f + (%.2f)*mileage' % (model.intercept_, model.coef_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нарисуйте предсказание модели (прямую) вместе с данными на плоскости. Здесь можно либо явно взять уравнение прямой и посчитать значения в каждой точке, либо через predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_train.plot(x='mileage', y='price', kind='scatter', s=120)\n",
    "\n",
    "## Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Меры качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно посчитать простые варианты агрегирования остатков, например:\n",
    "\n",
    "* $\\frac{1}{n} \\sum_i |\\hat{y}^{(i)}-y^{(i)}|$ - средняя абсолютная ошибка\n",
    "* $\\frac{1}{n} \\sum_i (\\hat{y}^{(i)}-y^{(i)})^2$ - средняя квадратичная ошибка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Средняя абсолютная ошибка %.2f' % mean_absolute_error(y_train, y_hat))\n",
    "print('Средняя квадратичная ошибка %.2f' % mean_squared_error(y_train, y_hat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно рассмотреть более сложную меру: коэффициент детерминации $R^2$:\n",
    "\n",
    "* $TSS = \\sum_i (y^{(i)}-\\bar{y})^2$ - общая сумма квадратов (total sum of squares)\n",
    "* $RSS = \\sum_i (\\hat{y}^{(i)}-y^{(i)})^2$ - сумма квадратов остатков (residual sum of squares)\n",
    "* $ESS = \\sum_i (\\hat{y}^{(i)}-\\bar{y})^2$ - объясненная сумма квадратов (explained sum of squares)\n",
    "\n",
    "Для простоты будем считать, что\n",
    "$$TSS = ESS + RSS$$\n",
    "\n",
    "Тогда Коэффициент детерминации $R^2=1-\\frac{RSS}{TSS}$\n",
    "\n",
    "Рассчитайте его для нашей модели\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Преобразование переменных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переход к близким или единым шкалам улучшает сходимость градиентного спуска, уменьшает риск переполнения разрядности чисел, однако приходится жертвовать прямой интерпретируемостью..\n",
    "\n",
    "Нормализацию обычно проделывают для вещественных признаков.\n",
    "\n",
    "Нормализация z-score:\n",
    "1. Вычитаем среднее: $x - \\bar{x}$\n",
    "2. Делим на стандартное отклонение: $\\frac{x - \\bar{x}}{std(x)}$\n",
    "\n",
    "Можно проделать вручную, можно с помошью метода ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "\n",
    "model = LinearRegression(fit_intercept=True)\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Модель:\\nprice = %.2f + (%.2f)*mileage`' % (model.intercept_, model.coef_[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Как обучать линейную регрессию?\n",
    "Попробуем разобраться без всяких `.predict()` и `.fit()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Рассмотрим случай с одним признаком и свободным членом"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$X$ - признаковое описание наблюдений,<br\\> $y$ - прогнозируемая величина\n",
    "\n",
    "Пусть задана функция ошибки (функция потерь) $L(\\cdot)$. <br\\>\n",
    "Нам надо построить такой функционал $f(X)$, который будет выдавать значение наиболее близкие к $y$, иначе говоря: $$L\\left(f(X) - y\\right) \\rightarrow\\min $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определим функцию потерь, как сумму квадратов разности выдаваемого ответа функционала и реального значения: \n",
    "$$ L(\\cdot) = \\frac{1}{2n}\\sum_{i=1}^n(f(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "Так как среди всего множества моделей мы выбрали линейную регрессию, то $$f(X) = \\beta_0 + \\beta_1x_1$$\n",
    "Подставляем это выражение в $L(\\cdot)$ и находим $\\beta_0$,\n",
    "$\\beta_1$!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ L(\\beta_0,\\beta_1) = \\frac{1}{2n}\\sum^{n}_{i=1}(f(x^{(i)})  - y^{(i)})^2 = \\frac{1}{2n}\\sum^{n}_{i=1}(\\beta_0 + \\beta_1x^{(i)}_1 - y^{(i)})^2  \\rightarrow \\min\\limits_{\\beta_0, \\beta_1} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изобразим функцию потерь на трехмерном графике в зависимости от $\\beta_0$ и $\\beta_1$ для задачи с автомобилем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# для удобства добавим столбец из \"1\" в матрицу с признаком \"пробег\"\n",
    "X_model = np.c_[np.ones(X_train.shape), X_train]\n",
    "X_model.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits import mplot3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta0 = np.linspace(11000 , 13000, 100)\n",
    "beta1 = np.linspace(-2450, -250, 100)\n",
    "\n",
    "B0, B1= np.meshgrid(beta0, beta1)\n",
    "\n",
    "B_all = np.c_[B0.reshape(-1,1), B1.reshape(-1,1)].T\n",
    "\n",
    "L = X_model.dot(B_all) - y_train.reshape(-1,1)\n",
    "L = L ** 2\n",
    "L = L.mean(axis=0)/2\n",
    "L = L.reshape(B0.shape)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(14, 7))\n",
    "ax = fig.add_subplot(1, 2, 1, projection='3d')\n",
    "ax.view_init(40, 25)\n",
    "ax.plot_surface(B0, B1, L, alpha=0.3,)\n",
    "ax.set_xlabel('beta_0')\n",
    "ax.set_ylabel('beta_1')\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "contour = ax.contour(B0, B1, L)\n",
    "plt.clabel(contour, inline=1, fontsize=10)\n",
    "ax.set_xlabel('beta_0')\n",
    "ax.set_ylabel('beta_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Градиентный спуск"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентый спуск - это итеративный метод оптимизации функции. Он заключается в постепенном перемещении к точке экспетмума в направлении антиградиента этой функции в точке."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитаем, чему равен градиент функции потерь $L(\\beta_0, \\beta_1):$\n",
    "$$ \\frac{\\partial L}{\\partial \\beta_0} = \\frac{1}{n}\\sum^{n}_{i=1}(\\beta_0 + \\beta_1x^{(i)}_1 - y^{(i)})$$\n",
    "$$ \\frac{\\partial L}{\\partial \\beta_1} = \\frac{1}{n}\\sum^{n}_{i=1}(\\beta_0 + \\beta_1x^{(i)}_1 - y^{(i)})x_1^{(i)}$$\n",
    "\n",
    "Иногда проще это записать в виде матриц:\n",
    "$$ \\frac{\\partial L}{\\partial \\beta} = X^\\top(X\\beta - y)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод градиентного спуска заключается в итеративном и **одновременном(!!!)** обновлении значений $\\beta$ в направлении, противоположному градиенту:\n",
    "$$ \\beta := \\beta -  \\frac{\\alpha}{n} \\frac{\\partial L}{\\partial \\beta}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь к шагам алгоритма:\n",
    "\n",
    "* Задаем случайное начальное значение для $\\beta$\n",
    "* Пока не будет достигнуто правило останова:\n",
    "    * Считаем ошибку и значение функции потерь\n",
    "    * Считаем градиент\n",
    "    * Обновляем коэффициенты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_descent(X, y, iters, alpha):\n",
    "    \n",
    "    costs = []\n",
    "    betas = []\n",
    "    \n",
    "    n = y.shape[0] \n",
    "    Beta = np.random.rand(X.shape[1])\n",
    "    for i in xrange(iters):\n",
    "        y_hat = X.dot(Beta)\n",
    "        \n",
    "        # считаем ошибку и значение функции потерь\n",
    "        \n",
    "        # считаем градиент\n",
    "\n",
    "        # обновляем коэффициенты\n",
    "        # Beta = Beta - alpha/n * grad\n",
    "                    \n",
    "    return Beta, costs, betas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Beta, costs, betas = gradient_descent(X_model, y_train, 100, 0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "beta0 = np.linspace(11000 , 13000, 100)\n",
    "beta1 = np.linspace(-2450, -250, 100)\n",
    "\n",
    "B0, B1= np.meshgrid(beta0, beta1)\n",
    "\n",
    "B_all = np.c_[B0.reshape(-1,1), B1.reshape(-1,1)].T\n",
    "\n",
    "L = X_model.dot(B_all) - y_train.reshape(-1,1)\n",
    "L = L ** 2\n",
    "L = L.mean(axis=0)/2\n",
    "L = L.reshape(B0.shape)\n",
    "\n",
    "fig, ax = plt.subplots(1,1)\n",
    "contour = ax.contour(B0, B1, L)\n",
    "plt.clabel(contour, inline=1, fontsize=10)\n",
    "ax.set_xlabel('beta_0')\n",
    "ax.set_ylabel('beta_1')\n",
    "\n",
    "betas = np.array(betas)\n",
    "ax.plot(betas[:,0], betas[:,1], marker='*')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (12,8)\n",
    "\n",
    "# Для кириллицы на графиках\n",
    "font = {'family': 'Verdana',\n",
    "        'weight': 'normal'}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Игрушечный пример"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сгенерируем выборку и опробуем логистическую регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "X = np.r_[np.random.randn(20, 2) + [2, 2],\n",
    "          np.random.randn(20, 2) + [-2, -2]]\n",
    "y = [-1] * 20 + [1] * 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(7, 7))\n",
    "ax.scatter(X[:, 0],\n",
    "           X[:, 1],\n",
    "           c=y,\n",
    "           cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучим логистическую регрессию на этих данных и нарисуем разделяющую гиперплоскость"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=1.0, \n",
    "                           fit_intercept=True, \n",
    "                           penalty='l2')\n",
    "model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 'w_0 = %f' % model.intercept_\n",
    "print 'w_1, w_2 = ', model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Нарисуем эту гиперплоскость\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat = model.predict(X)\n",
    "y_hat[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_hat_proba = model.predict_proba(X)\n",
    "y_hat_proba[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dec_func = model.decision_function(X)\n",
    "dec_func[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Как сделать нелинейную границу?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим набор данных, который в простонародье называют \"Бублик\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_circles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X, y = make_circles(n_samples=100, shuffle=True,\n",
    "                    noise = 0.1,\n",
    "                    factor=0.1)\n",
    "\n",
    "plt.scatter(X[:, 0],\n",
    "            X[:, 1],\n",
    "            c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что классы нельзя разделить линией. Но можно сделать это окружностью! </br>\n",
    "Т.е. разделяющся линия теперь будет задаваться не уравнением прямой $g(x) = w_0 + w_1x_1 + w_2x_2$, а уравнением окружности. \n",
    "\n",
    "Выполните преобразование матрицы X, чтобы в ней были столбцы для $x_1$, $x_2$, $x^2_1$ + $x^2_2$ и обучите логистическую регрессию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your code Here\n",
    "X_new = ...\n",
    "model = LogisticRegression(C=100000, \n",
    "                           fit_intercept=True)\n",
    "model.fit(X_new, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Посчитаем количество ошибок\n",
    "y_hat = model.predict(X_new)\n",
    "(y != y_hat).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Нарисуем полученную окружность\n",
    "\n",
    "x0, x1 = np.meshgrid(np.arange(-1.5, 1.5, 0.1),\n",
    "                       np.arange(-1.5, 1.5, 0.1))\n",
    "xx0, xx1 = x0.ravel(), x1.ravel()\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Анализ тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузите текстовые данные [отсюда](https://archive.ics.uci.edu/ml/machine-learning-databases/00331/). Архив должен содержать 3 файла с положительными и отрицательными отзывами с ресурсов\n",
    "* imdb.com\n",
    "* amazon.com\n",
    "* yelp.com\n",
    "\n",
    "Формат файла следующий:\n",
    "<отзыв>\\t<метка>\\n\n",
    "\n",
    "\n",
    "### Задача\n",
    "1. Загрузите тексты и метки классов в разные переменные\n",
    "2. Выберите меру качества классификации\n",
    "3. Обучите логистическую (без подбора гиперпараметров). Тексты представляются в виде мешка слов\n",
    "4. Выведите наиболее значимые слова из текста"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_data = pd.read_csv('sentiment/yelp_labelled.txt', sep='\\t', names=['sentence', 'label'], header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sent_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = sent_data.sentence.values\n",
    "y = sent_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Code Here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sberbank DS Contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этом задании мы рассмотрим данные с предыдущего Sberbank Data Science Contest. К сожалению найти страницу с конкурсом уже не получается.\n",
    "\n",
    "Одной из задач была опредление пола владельца карты по его транзакциям на карте. Зачем это нужно - одному сберу известно, но эта задача была хороша тем, что в ней можно нагенерировать много разных признаков\n",
    "\n",
    "Есть такая [презентация](https://alexanderdyakonov.files.wordpress.com/2016/10/dj2016_sdsj_vis.pdf) с предварительным анализом данных и идеями про признаки\n",
    "\n",
    "Нам понадобятся файлы `customers_gender_train.csv`, `transactions.tsv.gz`, `mcc_types.tsv` и `trans_types.tsv`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Посмотрим на данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это метки ответов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_gender = pd.read_csv('data/customers_gender_train.csv')\n",
    "df_gender.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это сами транзакции (отрицательные транзакции - списывание, положительные - зачисление на счет)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transactions = pd.read_csv('data/transactions.csv.gz')\n",
    "df_transactions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее, расшифровки кодов [mcc](https://ru.wikipedia.org/wiki/Merchant_Category_Code) и транзакций"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_tr = pd.read_csv('data/tr_types.csv', sep=';', encoding='utf8')\n",
    "df_tr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_mcc = pd.read_csv('data/tr_mcc_codes.csv', sep=';', encoding='utf8')\n",
    "df_mcc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первое что мы видем - это странная дата и суммы в транзакциях. \n",
    "\n",
    "В принципе, посмотрев на исходное распределение \"относительных\" дат по какой-нибудь гендерной группы mcc, становится примерно понятно, что за даты закодированы.\n",
    "\n",
    "Ну а суммы транзакций организаторы просто умножили на $\\pi^{\\exp}$ =)\n",
    "\n",
    "Преобразование будет проделано ниже, но при желании, можете сами со всем разобраться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import Timestamp, DateOffset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preproc_transactions(df_transactions):\n",
    "    sec_per_day = 86400\n",
    "    sec_per_hour = 3600\n",
    "    \n",
    "    start_date = 1420070400 - 154 * sec_per_day - 3 * sec_per_hour\n",
    "    \n",
    "    df_transactions.loc[:, 'day'] = df_transactions.tr_datetime\\\n",
    "                                               .str.split(' ')\\\n",
    "                                               .str.get(0)\\\n",
    "                                               .astype(int)\n",
    "    df_transactions.loc[:, 'time_raw'] = df_transactions.tr_datetime\\\n",
    "                                                    .str.split(' ')\\\n",
    "                                                    .str.get(1)\n",
    "\n",
    "    # set temp dt\n",
    "    df_transactions.loc[:, 'dt_temp'] = pd.to_datetime(df_transactions.loc[:, 'time_raw'], \n",
    "                                                    format='%H:%M:%S')\\\n",
    "                                        + DateOffset(years=115)\n",
    "    \n",
    "    df_transactions = df_transactions.assign(dt = lambda x: x.dt_temp.astype(np.int64) // 10**9\n",
    "                                             + (x.day - 153) * sec_per_day)\\\n",
    "                                     .assign(weekday = lambda x: ((x.day + 4) % 7 + 1))\n",
    "        \n",
    "    df_transactions.loc[:, 'datetime'] = pd.to_datetime(df_transactions.dt, unit='s')\n",
    "    df_transactions.loc[:, 'date'] = df_transactions.loc[:, 'datetime'].dt.strftime('%Y-%m-%d')\n",
    "    df_transactions.loc[:, 'hour'] = df_transactions.loc[:, 'datetime'].dt.strftime('%H')\n",
    "    \n",
    "    df_transactions = df_transactions.drop(['dt_temp', 'time_raw', 'tr_datetime'], axis=1)\n",
    "    \n",
    "    df_transactions.loc[:, 'amount'] = np.round(df_transactions.loc[:, 'amount']/(np.pi**np.exp(1)))\n",
    "            \n",
    "    return df_transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_transactions = df_transactions.pipe(preproc_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Генерим признаки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Для котого мы делаем предсказания?\n",
    "* Какие признаки этих объектов мы можем рассчитать?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_features(df_gender, df_transactions):\n",
    "        \n",
    "    return df_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_features = df_gender.pipe(gen_features, df_transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df_features.loc[:, idx_features].values\n",
    "y = df_features.loc[:, ~idx_features].values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбор гипер-параметров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем простой sklearn пайплайн, который делает следующее:\n",
    "* Нормирует признаки через StandartScaler\n",
    "* Запускает лог-регрессию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Pipeline([\n",
    "    ...\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RND_SEED = 123"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "До этого мы исключительно смотрели, как влияет на меру качества какой-то один параметр при фиксированных остальных. Пришло время перебирать все что можно!\n",
    "\n",
    "В базовом варианте, это делается либо через `Grid Search`, либо через `Random Search`. Какие ключевые отличия?\n",
    "* В `Grid Search` вы в явнов виде задаете возможные значения каждого гипер-параметра, который хотите варьировать. Соответственно, выполняется **полный** перебор всех возможных комбинаций\n",
    "* В `Random Search` допукается указание распределения параметров, например \"равномерно, на интервале от 0 до 100\" или \"нормальное распределение с таким-то цетром и такой-то дисперсией. Соответственно, так как это случайный перебор, то **вы** просто **задаете** количество случайных комбинаций, которые будут проверяться\n",
    "\n",
    "Может показаться, что делать случайный перебор опасно - там же все случайно. Но на практике именно он и искользуется в силу двух причин\n",
    "* Полный перебор большого количества комбинаций очень долгий\n",
    "* Мы можем просто пропустить значения гиперпараметра, которые сильно влияют на метрику качества (см рисунок снизу)\n",
    "\n",
    "<img src='images/gridsearch.jpeg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, random_state=RND_SEED, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'scaler__with_mean': [False, True],\n",
    "    'clf__penalty': ['l2'],\n",
    "    'clf__random_state': [RND_SEED],\n",
    "    'clf__C': sp_lognorm(4)\n",
    "}\n",
    "\n",
    "random_searcher = RandomizedSearchCV(model, param_grid, n_iter=100, \n",
    "                                     random_state=RND_SEED,\n",
    "                                     scoring='roc_auc', \n",
    "                                     n_jobs=-1, cv=cv, \n",
    "                                     verbose=2)\n",
    "\n",
    "random_searcher.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nav_menu": {},
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "476px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
